{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Colab instructions",
   "id": "2125209de034f326"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!git clone https://github.com/GioC1810/aml23-ego.git\n",
    "!pip install omegaconf coloredlogs wandb"
   ],
   "id": "77bdeb2ad5636f8d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Compress a file",
   "id": "abe56a606b503860"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T14:19:26.609040Z",
     "start_time": "2024-04-26T14:18:15.430156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lzma\n",
    "\n",
    "with open('saved_features_action_net/new_emg_spectrogram_train.pkl', 'rb') as f_in:\n",
    "    with lzma.open('saved_features_action_net/new_emg_spectrogram_train.pkl.xz', 'wb') as f_out:\n",
    "        f_out.write(f_in.read())"
   ],
   "id": "3bc8579d8ce1001b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Epic kitchen",
   "id": "5cd103ec49d743a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Feature extraction script",
   "id": "88bbd56a11a4d043"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The script extract the features for 5, 10 and 25 num frames per clip",
   "id": "b9fbc7a388f05bb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "splits=(\"test\" \"train\")\n",
    "num_frames=(5 10 25)\n",
    "dense_sampling=(\"True\" \"False\")\n",
    "\n",
    "for split in ${splits[@]}\n",
    "do\n",
    "  for frames in ${num_frames[@]}\n",
    "  do\n",
    "    for sampling in ${dense_sampling[@]}\n",
    "    do\n",
    "        python3 save_feat.py name=feature_extraction_D1 \\\n",
    "            config=configs/I3D_save_feat.yaml \\\n",
    "            dataset.shift=D1-D1 \\\n",
    "            save.num_frames_per_clip.RGB=$frames \\\n",
    "            save.dense_sampling.RGB=$sampling \\\n",
    "            dataset.RGB.data_path=../ek_data/frames \n",
    "    done\n",
    "  done\n",
    "done\n",
    "\n"
   ],
   "id": "e27164192932022",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Model training",
   "id": "8f507c86877d6c74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Indicate shift, num frames per clip and model to use",
   "id": "32241bbc653b2fe5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "python3 train_classifier_ek.py name=model_name \\\n",
    "  config=configs/default.yaml \\\n",
    "  dataset.shift=D1-D1 \\\n",
    "  dataset.train.num_frames_per_clip.RGB=5 \\\n",
    "  dataset.models.RGB=TRN_classifier"
   ],
   "id": "d69cda3bf11ff251",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Action net",
   "id": "1becac1540863443"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Action net frame extraction",
   "id": "dd5f6841c4192ef0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%bash\n",
    "\n",
    "ffmpeg -i action-net/video/S04_video.mp4 -vf \"fps=30,scale=456:256\" -q:v 2 action-net/frames/S04_1/frame_%010d.jpg"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Feature rgb extraction\n",
    "Indicate num frames per clip"
   ],
   "id": "2c1ac95cbad15530"
  },
  {
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "python3 save_feat_action_net.py name=feature_rgb_extracted \\\n",
    "  config=configs/I3D_save_feat_an.yaml \\\n",
    "  save.dense_sampling.RGB=True \\\n",
    "  save.num_frames_per_clip.RGB=5 \\\n",
    "  split=train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T09:41:42.408740Z",
     "start_time": "2024-04-27T09:41:25.805629Z"
    }
   },
   "id": "79e7a82f5923f8c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 11:41:27 LOG INFO Feature Extraction\n",
      "2024-04-27 11:41:27 LOG INFO Running with parameters: \n",
      "  action: save\n",
      "  name: feature_rgb_extracted\n",
      "  modality: ['RGB']\n",
      "  total_batch: 128\n",
      "  batch_size: 32\n",
      "  gpus: None\n",
      "  wandb_name: None\n",
      "  resume_from: ./saved_models/I3D_SourceOnlyD1\n",
      "  logname: save_D1-S04.log\n",
      "  models_dir: models\n",
      "  aggregation: True\n",
      "  train:\n",
      "    num_iter: 5000\n",
      "    lr_steps: 3000\n",
      "    eval_freq: 50\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 5\n",
      "  test:\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 5\n",
      "  dataset:\n",
      "    annotations_path: action_net_annotations_training\n",
      "    shift: D1-S04\n",
      "    workers: 4\n",
      "    stride: 2\n",
      "    resolution: 224\n",
      "    num_classes: 8\n",
      "    RGB:\n",
      "      data_path: action-net/frames\n",
      "      tmpl: frame_{:010d}.jpg\n",
      "      features_name: saved_features\n",
      "    Event:\n",
      "      rgb4e: 6\n",
      "  models:\n",
      "    RGB:\n",
      "      model: I3D\n",
      "      normalize: False\n",
      "      kwargs:\n",
      "      lr_steps: 3000\n",
      "      lr: 0.01\n",
      "      sgd_momentum: 0.9\n",
      "      weight_decay: 1e-07\n",
      "      dropout: 0.5\n",
      "      resolution: 224\n",
      "      weight_i3d_rgb: ./pretrained_i3d/rgb_imagenet.pt\n",
      "  split: train\n",
      "  features_path: ['saved_features_action_net']\n",
      "  save:\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 5\n",
      "  config: configs/I3D_save_feat_an.yaml\n",
      "  experiment_dir: feature_rgb_extracted/Apr27_11-41-25\n",
      "  log_dir: TEST_RESULTS/feature_rgb_extracted\n",
      "  logfile: TEST_RESULTS/feature_rgb_extracted/save_D1-S04.log\n",
      "2024-04-27 11:41:27 LOG INFO Instantiating models per modality\n",
      "2024-04-27 11:41:27 LOG INFO I3D Net\tModality: RGB\n",
      "2024-04-27 11:41:27 LOG INFO Loading Kinetics weights I3D\n",
      "2024-04-27 11:41:27 LOG INFO  * Skipping Logits weight for 'logits.conv3d.weight'\n",
      "2024-04-27 11:41:27 LOG INFO  * Skipping Logits weight for 'logits.conv3d.bias'\n",
      "2024-04-27 11:41:27 LOG INFO Restoring action-classifier for modality RGB from saved_models/I3D_SourceOnlyD1/Oct25_22-38-50/action-classifier_RGB_9.pth\n",
      "2024-04-27 11:41:27 LOG INFO RGB-Model for action-classifier restored at iter 4850.0\n",
      "Best accuracy on val: 59.54 at iter 4000.0\n",
      "Last accuracy on val: 58.85\n",
      "Last loss: 0.00\n",
      "2024-04-27 11:41:27 LOG INFO Dataloader for S04-train with 735 samples generated\n",
      "2024-04-27 11:41:33 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x31bdccfd0>\n",
      "2024-04-27 11:41:33 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x14b1ce0d0>\n",
      "2024-04-27 11:41:33 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x14a5ce3d0>\n",
      "2024-04-27 11:41:33 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x319cce890>\n",
      "2024-04-27 11:41:34 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x31bdcf090>\n",
      "2024-04-27 11:41:34 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x14a5e04d0>\n",
      "2024-04-27 11:41:34 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x319ce09d0>\n",
      "2024-04-27 11:41:34 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x14b1dc110>\n",
      "2024-04-27 11:41:34 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x31bde11d0>\n",
      "2024-04-27 11:41:34 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x14b1de210>\n",
      "2024-04-27 11:41:35 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x14a5e25d0>\n",
      "2024-04-27 11:41:35 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x319ce2ad0>\n",
      "2024-04-27 11:41:36 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x31bde32d0>\n",
      "2024-04-27 11:41:36 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x14b1e8350>\n",
      "2024-04-27 11:41:37 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x14a5e8710>\n",
      "2024-04-27 11:41:37 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x319ce8c10>\n",
      "2024-04-27 11:41:38 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x31bde9410>\n",
      "2024-04-27 11:41:38 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x14b1ea450>\n",
      "2024-04-27 11:41:39 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x14a5ea810>\n",
      "2024-04-27 11:41:40 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x319cead10>\n",
      "2024-04-27 11:41:41 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x31bdeb510>\n",
      "2024-04-27 11:41:41 LOG INFO RECORD; <utils.epic_record.EpicVideoRecord object at 0x14b1f4590>\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "python3 save_feat_action_net.py\n",
    "  config=configs/I3D_save_feat_an.yaml \\\n",
    "  split=test \\\n",
    "  dataset.train.num_frames_per_clip.RGB=25 \\"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T09:23:17.142988Z",
     "start_time": "2024-04-27T09:23:15.362850Z"
    }
   },
   "id": "1cfe14a1c20ba95",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 11:23:16 LOG INFO Feature Extraction\n",
      "2024-04-27 11:23:16 LOG INFO Running with parameters: \n",
      "  action: train\n",
      "  name: test\n",
      "  modality: ['RGB']\n",
      "  total_batch: 128\n",
      "  batch_size: 32\n",
      "  gpus: None\n",
      "  wandb_name: None\n",
      "  resume_from: None\n",
      "  logname: None\n",
      "  models_dir: models\n",
      "  aggregation: True\n",
      "  train:\n",
      "    num_iter: 5000\n",
      "    lr_steps: 3000\n",
      "    eval_freq: 50\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 5\n",
      "  test:\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 5\n",
      "  dataset:\n",
      "    annotations_path: train_val\n",
      "    shift: D1-D1\n",
      "    workers: 4\n",
      "    stride: 2\n",
      "    resolution: 224\n",
      "    num_classes: 20\n",
      "    RGB:\n",
      "      data_path: saved_features\n",
      "      tmpl: img_{:010d}.jpg\n",
      "      features_name: saved_features\n",
      "    Event:\n",
      "      rgb4e: 6\n",
      "  models:\n",
      "    RGB:\n",
      "      model: TRN_classifier\n",
      "      normalize: False\n",
      "      kwargs:\n",
      "      lr_steps: 3000\n",
      "      lr: 0.01\n",
      "      sgd_momentum: 0.9\n",
      "      weight_decay: 1e-07\n",
      "  experiment_dir: test/Apr27_11-23-15\n",
      "  log_dir: Experiment_logs/test/Apr27_11-23-15\n",
      "  logfile: Experiment_logs/test/Apr27_11-23-15/train.log\n",
      "2024-04-27 11:23:16 LOG INFO Instantiating models per modality\n",
      "2024-04-27 11:23:16 LOG INFO TRN_classifier Net\tModality: RGB\n",
      "2024-04-27 11:23:16 LOG ERROR Uncaught exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giorgiocacopardi/Documents/Magistrale/2anno/AdvancedMachineLearning/ExamProject/aml23-ego/save_feat_action_net.py\", line 167, in <module>\n",
      "    main()\n",
      "  File \"/Users/giorgiocacopardi/Documents/Magistrale/2anno/AdvancedMachineLearning/ExamProject/aml23-ego/save_feat_action_net.py\", line 49, in main\n",
      "    models[m] = getattr(model_list, args.models[m].model)(num_classes, m, args.models[m], **args.models[m].kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giorgiocacopardi/Documents/Magistrale/2anno/AdvancedMachineLearning/ExamProject/aml23-ego/models/TRN_classifier.py\", line 12, in __init__\n",
      "    self.scales = [i for i in range(num_frames, 1, -1)] #\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'str' object cannot be interpreted as an integer\n",
      "bash: line 3: dataset.train.num_frames_per_clip.RGB=25: command not found\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'\\npython3 save_feat_action_net.py\\n  config=configs/I3D_save_feat_an.yaml \\\\\\n  split=test \\\\\\n  dataset.train.num_frames_per_clip.RGB=25 \\\\\\n'' returned non-zero exit status 127.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mCalledProcessError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_cell_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbash\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43mpython3 save_feat_action_net.py\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m  config=configs/I3D_save_feat_an.yaml \u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m  split=test \u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m  dataset.train.num_frames_per_clip.RGB=25 \u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2493\u001B[0m, in \u001B[0;36mInteractiveShell.run_cell_magic\u001B[0;34m(self, magic_name, line, cell)\u001B[0m\n\u001B[1;32m   2491\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[1;32m   2492\u001B[0m     args \u001B[38;5;241m=\u001B[39m (magic_arg_s, cell)\n\u001B[0;32m-> 2493\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2495\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[1;32m   2496\u001B[0m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[1;32m   2497\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[1;32m   2498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/IPython/core/magics/script.py:154\u001B[0m, in \u001B[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001B[0;34m(line, cell)\u001B[0m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    153\u001B[0m     line \u001B[38;5;241m=\u001B[39m script\n\u001B[0;32m--> 154\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshebang\u001B[49m\u001B[43m(\u001B[49m\u001B[43mline\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcell\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/IPython/core/magics/script.py:314\u001B[0m, in \u001B[0;36mScriptMagics.shebang\u001B[0;34m(self, line, cell)\u001B[0m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39mraise_error \u001B[38;5;129;01mand\u001B[39;00m p\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    310\u001B[0m     \u001B[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001B[39;00m\n\u001B[1;32m    311\u001B[0m     \u001B[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001B[39;00m\n\u001B[1;32m    312\u001B[0m     \u001B[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001B[39;00m\n\u001B[1;32m    313\u001B[0m     rc \u001B[38;5;241m=\u001B[39m p\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m9\u001B[39m\n\u001B[0;32m--> 314\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CalledProcessError(rc, cell)\n",
      "\u001B[0;31mCalledProcessError\u001B[0m: Command 'b'\\npython3 save_feat_action_net.py\\n  config=configs/I3D_save_feat_an.yaml \\\\\\n  split=test \\\\\\n  dataset.train.num_frames_per_clip.RGB=25 \\\\\\n'' returned non-zero exit status 127."
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Decompress emg features train",
   "id": "e75d81c9cbf27a62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T14:20:31.107328Z",
     "start_time": "2024-04-24T14:20:28.275240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lzma\n",
    "\n",
    "with lzma.open('saved_features_an_multimodal/features_emg_allData_train.pkl.xz', 'rb') as f_in:\n",
    "    with open('saved_features_an_multimodal/features_emg_allData_train.pkl', 'wb') as f_out:\n",
    "        f_out.write(f_in.read())\n",
    "        "
   ],
   "id": "887140ea2ee6a9f9",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Split emg spectogram features in order to push it",
   "id": "27ce084d7eb3589a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T20:03:35.261118Z",
     "start_time": "2024-04-26T20:03:29.403763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "def split_dict(filename, output_prefix):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    length = len(data['features'])\n",
    "    third_length = length // 3\n",
    "\n",
    "    split = [data['features'][0:third_length], data['features'][third_length:2*third_length], data['features'][2*third_length:length]]\n",
    "\n",
    "    for i in range(1,4):\n",
    "        with open(output_prefix + f'_{i}.pkl', 'wb') as f:\n",
    "            pickle.dump(split[i-1], f)\n",
    "\n",
    "split_dict('saved_features_an_multimodal/features_emg_spectrogram_train.pkl', 'saved_features_an_multimodal/features_emg_spectrogram_train_split')"
   ],
   "id": "1a3d0661e70becf0",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Decompress and join emg spectogram features",
   "id": "40d10489a0c05d89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T20:14:19.797582Z",
     "start_time": "2024-04-26T20:14:13.449256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "def join_spectogram_feature(filename, output_name):\n",
    "    joined_features = {'features': []}\n",
    "    \n",
    "    for i in range(3):\n",
    "        with open(filename + f'_{i+1}.pkl', 'rb') as f:\n",
    "            joined_features['features'].extend(pickle.load(f))\n",
    "            \n",
    "    \n",
    "    with open(output_name, 'wb') as f:\n",
    "        pickle.dump(joined_features, f)\n",
    "        \n",
    "join_spectogram_feature('saved_features_an_multimodal/features_emg_spectrogram_train_split', \n",
    "                        'saved_features_an_multimodal/features_emg_spectrogram_train.pkl')"
   ],
   "id": "1379477bc51d351",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Model training",
   "id": "42e4ea77e6012e6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "python3 train_classifier.py name=train_model_rgb \\\n",
    "  config=configs/default_an_rgb.yaml \\\n",
    "  train.dense_sampling.RGB=True \\\n",
    "  train.num_frames_per_clip.RGB=25 \\\n",
    "  dataset.models.RGB=TRN_classifier"
   ],
   "id": "8f6ed977d2987778",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Multimodal models\n",
   "id": "70b5fda69a888d6b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Late fusion model",
   "id": "8dcb5014ce9682cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### Testing",
   "id": "382f7a6ddf5c03aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%bash\n",
    "\n",
    "python3 train_classifier_multimodal.py name=multimodal \\\n",
    "  config=configs/multimodal_an.yaml \\\n",
    "  train.dense_sampling.RGB=True \\\n",
    "  train.num_frames_per_clip.RGB=25 \\\n",
    "  models.RGB.model=Lstm_classifier \\\n",
    "  models.EMG.model=EMG_LSTM"
   ],
   "id": "320a343b4d4f7fe7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Midl level fusion model",
   "id": "7014e16224fe3ea5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### Mid level feature extraction",
   "id": "1de3368a41064636"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### Training",
   "id": "c04c0ec4ae357cd2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "python3 save_feat_midlevel_multimodal.py name=midlevel_feat \\\n",
    "  config=configs/mid_level_extraction.yaml \\\n",
    "  split=test\n",
    "  save.dense_sampling.RGB=True \\\n",
    "  save.num_frames_per_clip.RGB=25 \\\n",
    "  models.RGB.model=TRN_classifier \\\n",
    "  models.EMG.model=EMG_LSTM"
   ],
   "id": "cf5a78f161f7f822",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T17:25:30.698445Z",
     "start_time": "2024-04-28T17:24:33.531777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "python3 train_midlevel_classifier.py name=midlevel_classifier \\\n",
    "  config=configs/multimodal_midLevel_an.yaml \\\n",
    "  train.dense_sampling.RGB=True \\\n",
    "  train.num_frames_per_clip.RGB=25"
   ],
   "id": "75331fccbedba134",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-28 19:24:37 LOG INFO Running with parameters: \n",
      "  action: train\n",
      "  name: midllevel_classifier\n",
      "  modality: ['FUSION']\n",
      "  total_batch: 128\n",
      "  batch_size: 32\n",
      "  gpus: None\n",
      "  wandb_name: None\n",
      "  resume_from:\n",
      "    FUSION: None\n",
      "  logname: None\n",
      "  models_dir: saved_models\n",
      "  aggregation: True\n",
      "  train:\n",
      "    num_iter: 5000\n",
      "    lr_steps: 3000\n",
      "    eval_freq: 50\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 25\n",
      "  test:\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 5\n",
      "  dataset:\n",
      "    annotations_path: an_multimodal_annotations\n",
      "    shift: S04-S04\n",
      "    workers: 4\n",
      "    stride: 2\n",
      "    resolution: 224\n",
      "    num_classes: 20\n",
      "    RGB:\n",
      "      data_path: saved_features\n",
      "      tmpl: img_{:010d}.jpg\n",
      "      features_name: saved_features\n",
      "    Event:\n",
      "      rgb4e: 6\n",
      "    FUSION:\n",
      "      data_path: mid_level_features\n",
      "      tmpl: img_{:010d}.jpg\n",
      "      features_name: midlevel_feat\n",
      "  models:\n",
      "    RGB:\n",
      "      model: TRN_classifier\n",
      "      normalize: False\n",
      "      kwargs:\n",
      "      lr_steps: 3000\n",
      "      lr: 0.01\n",
      "      sgd_momentum: 0.9\n",
      "      weight_decay: 1e-07\n",
      "    FUSION:\n",
      "      model: FullyConnectedFusion\n",
      "      normalize: False\n",
      "      kwargs:\n",
      "      lr_steps: 3000\n",
      "      lr: 0.01\n",
      "      sgd_momentum: 0.9\n",
      "      weight_decay: 1e-07\n",
      "  config: configs/multimodal_midLevel_an.yaml\n",
      "  experiment_dir: midllevel_classifier/Apr28_19-24-33\n",
      "  log_dir: Experiment_logs/midllevel_classifier/Apr28_19-24-33\n",
      "  logfile: Experiment_logs/midllevel_classifier/Apr28_19-24-33/train.log\n",
      "2024-04-28 19:24:37 LOG INFO Instantiating models per modality\n",
      "2024-04-28 19:24:37 LOG INFO FullyConnectedFusion Net\tModality: FUSION\n",
      "2024-04-28 19:24:37 LOG INFO Dataloader for S04-train with 735 samples generated\n",
      "2024-04-28 19:24:37 LOG INFO Dataloader for S04-train with 735 samples generated\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 0/20000 batch retrieved! Elapsed time = 0.0 m 0.23387 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 1/20000 batch retrieved! Elapsed time = 0.0 m 0.000994 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 2/20000 batch retrieved! Elapsed time = 0.0 m 0.000185 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 3/20000 batch retrieved! Elapsed time = 0.0 m 0.00024 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO [1/5000]\tlast Verb loss: 0.1486\tMean verb loss: 0.1489\tAcc@1: 15.62%\tAccMean@1: 14.06%\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 4/20000 batch retrieved! Elapsed time = 0.0 m 0.000392 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 5/20000 batch retrieved! Elapsed time = 0.0 m 0.000654 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 6/20000 batch retrieved! Elapsed time = 0.0 m 0.000305 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 7/20000 batch retrieved! Elapsed time = 0.0 m 0.000118 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO [2/5000]\tlast Verb loss: 0.1478\tMean verb loss: 0.1482\tAcc@1: 18.75%\tAccMean@1: 17.97%\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 8/20000 batch retrieved! Elapsed time = 0.0 m 0.000102 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 9/20000 batch retrieved! Elapsed time = 0.0 m 0.000644 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 10/20000 batch retrieved! Elapsed time = 0.0 m 0.000364 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 11/20000 batch retrieved! Elapsed time = 0.0 m 0.000427 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO [3/5000]\tlast Verb loss: 0.1475\tMean verb loss: 0.1478\tAcc@1: 28.12%\tAccMean@1: 22.66%\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 12/20000 batch retrieved! Elapsed time = 0.0 m 0.000734 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 13/20000 batch retrieved! Elapsed time = 0.0 m 0.000918 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 14/20000 batch retrieved! Elapsed time = 0.0 m 0.000713 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 15/20000 batch retrieved! Elapsed time = 0.0 m 0.003788 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO [4/5000]\tlast Verb loss: 0.1462\tMean verb loss: 0.1462\tAcc@1: 34.38%\tAccMean@1: 33.59%\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 16/20000 batch retrieved! Elapsed time = 0.0 m 0.001113 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 17/20000 batch retrieved! Elapsed time = 0.0 m 0.000506 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 18/20000 batch retrieved! Elapsed time = 0.0 m 0.00071 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 19/20000 batch retrieved! Elapsed time = 0.0 m 0.000713 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO [5/5000]\tlast Verb loss: 0.1453\tMean verb loss: 0.1460\tAcc@1: 37.50%\tAccMean@1: 35.16%\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 20/20000 batch retrieved! Elapsed time = 0.0 m 0.000918 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:24:47 LOG INFO Iteration 21/20000 batch retrieved! Elapsed time = 0.0 m 0.000613 s\n",
      "2024-04-28 19:24:47 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 22/20000 batch retrieved! Elapsed time = 0.0 m 26.888537 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 23/20000 batch retrieved! Elapsed time = 0.0 m 0.000438 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO [6/5000]\tlast Verb loss: 0.1443\tMean verb loss: 0.1435\tAcc@1: 40.62%\tAccMean@1: 42.97%\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 24/20000 batch retrieved! Elapsed time = 0.0 m 0.000365 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 25/20000 batch retrieved! Elapsed time = 0.0 m 9.9e-05 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 26/20000 batch retrieved! Elapsed time = 0.0 m 0.001303 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 27/20000 batch retrieved! Elapsed time = 0.0 m 0.002341 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO [7/5000]\tlast Verb loss: 0.1415\tMean verb loss: 0.1409\tAcc@1: 43.75%\tAccMean@1: 48.44%\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 28/20000 batch retrieved! Elapsed time = 0.0 m 8.3e-05 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 29/20000 batch retrieved! Elapsed time = 0.0 m 8.9e-05 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 30/20000 batch retrieved! Elapsed time = 0.0 m 0.00031 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 31/20000 batch retrieved! Elapsed time = 0.0 m 0.000365 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO [8/5000]\tlast Verb loss: 0.1404\tMean verb loss: 0.1415\tAcc@1: 43.75%\tAccMean@1: 37.50%\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 32/20000 batch retrieved! Elapsed time = 0.0 m 0.000456 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 33/20000 batch retrieved! Elapsed time = 0.0 m 9.2e-05 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 34/20000 batch retrieved! Elapsed time = 0.0 m 0.000308 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 35/20000 batch retrieved! Elapsed time = 0.0 m 0.000245 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO [9/5000]\tlast Verb loss: 0.1364\tMean verb loss: 0.1378\tAcc@1: 50.00%\tAccMean@1: 49.22%\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 36/20000 batch retrieved! Elapsed time = 0.0 m 0.000871 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 37/20000 batch retrieved! Elapsed time = 0.0 m 0.000298 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 38/20000 batch retrieved! Elapsed time = 0.0 m 0.000209 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 39/20000 batch retrieved! Elapsed time = 0.0 m 0.000207 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO [10/5000]\tlast Verb loss: 0.1366\tMean verb loss: 0.1356\tAcc@1: 46.88%\tAccMean@1: 45.31%\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 40/20000 batch retrieved! Elapsed time = 0.0 m 0.000279 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 41/20000 batch retrieved! Elapsed time = 0.0 m 0.000884 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 42/20000 batch retrieved! Elapsed time = 0.0 m 0.000386 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO Iteration 43/20000 batch retrieved! Elapsed time = 0.0 m 0.000253 s\n",
      "2024-04-28 19:25:14 LOG INFO FEATURE: torch.Size([32, 512])\n",
      "2024-04-28 19:25:14 LOG INFO [11/5000]\tlast Verb loss: 0.1299\tMean verb loss: 0.1332\tAcc@1: 53.12%\tAccMean@1: 50.78%\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giorgiocacopardi/Documents/Magistrale/2anno/AdvancedMachineLearning/ExamProject/aml23-ego/train_midlevel_classifier.py\", line 232, in <module>\n",
      "    main()\n",
      "  File \"/Users/giorgiocacopardi/Documents/Magistrale/2anno/AdvancedMachineLearning/ExamProject/aml23-ego/train_midlevel_classifier.py\", line 92, in main\n",
      "    train(action_classifier, train_loader, train_loader, device, num_classes)\n",
      "  File \"/Users/giorgiocacopardi/Documents/Magistrale/2anno/AdvancedMachineLearning/ExamProject/aml23-ego/train_midlevel_classifier.py\", line 131, in train\n",
      "    source_data, source_label = next(data_loader_source)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1318, in _next_data\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/connection.py\", line 947, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "execution_count": 59
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
