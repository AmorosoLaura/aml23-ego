{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Colab instructions",
   "id": "2125209de034f326"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!git clone https://github.com/GioC1810/aml23-ego.git\n",
    "!pip install omegaconf coloredlogs wandb"
   ],
   "id": "77bdeb2ad5636f8d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Epic kitchen",
   "id": "5cd103ec49d743a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Feature extraction script",
   "id": "88bbd56a11a4d043"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The script extract the features for 5, 10 and 25 num frames per clip",
   "id": "b9fbc7a388f05bb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "splits=(\"test\")\n",
    "num_frames=(5)\n",
    "dense_sampling=(\"True\")\n",
    "\n",
    "for split_type in ${splits[@]}\n",
    "do\n",
    "  for frames in ${num_frames[@]}\n",
    "  do\n",
    "    for sampling in ${dense_sampling[@]}\n",
    "    do\n",
    "        python3 save_feat.py \\\n",
    "            config=configs/I3D_save_feat.yaml \\\n",
    "            dataset.shift=D1-D1 \\\n",
    "            save.num_frames_per_clip.RGB=$frames \\\n",
    "            save.dense_sampling.RGB=$sampling \\\n",
    "            split=$split_type \\\n",
    "            dataset.RGB.data_path=./ek_data/frames \n",
    "    done\n",
    "  done\n",
    "done"
   ],
   "id": "e27164192932022",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Model training",
   "id": "8f507c86877d6c74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Indicate:\n",
    "- shift \n",
    "- num frames per clip  \n",
    "- model \n",
    "- model name"
   ],
   "id": "32241bbc653b2fe5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "python3 train_classifier_ek.py name=model_name \\\n",
    "  config=configs/default.yaml \\\n",
    "  dataset.shift=D1-D1 \\\n",
    "  train.num_frames_per_clip.RGB=5 \\\n",
    "  train.dense_sampling.RGB=True \\\n",
    "  models.RGB=TRN_classifier"
   ],
   "id": "d69cda3bf11ff251",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Action net",
   "id": "1becac1540863443"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Action net frame extraction",
   "id": "dd5f6841c4192ef0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%bash\n",
    "\n",
    "ffmpeg -i action-net/video/S04_video.mp4 -vf \"fps=30,scale=456:256\" -q:v 2 action-net/frames/S04_1/frame_%010d.jpg"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Feature rgb extraction\n",
    "Indicate:\n",
    "- num frames per clip\n",
    "- split (train or test)\n",
    "- dense sampling (True or False)"
   ],
   "id": "2c1ac95cbad15530"
  },
  {
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "python3 save_feat_action_net.py \\\n",
    "  config=configs/feature_rgb_extraction.yaml \\\n",
    "  save.dense_sampling.RGB=True \\\n",
    "  save.num_frames_per_clip.RGB=5 \\\n",
    "  split=test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79e7a82f5923f8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Decompress emg features train\n",
    "\n",
    "In order to push the features we compressed them, this script decompress them"
   ],
   "id": "e75d81c9cbf27a62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T14:20:31.107328Z",
     "start_time": "2024-04-24T14:20:28.275240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lzma\n",
    "\n",
    "with lzma.open('saved_features_an_multimodal/features_emg_allData_train.pkl.xz', 'rb') as f_in:\n",
    "    with open('saved_features_an_multimodal/features_emg_allData_train.pkl', 'wb') as f_out:\n",
    "        f_out.write(f_in.read())"
   ],
   "id": "887140ea2ee6a9f9",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Split emg spectogram features in order to push it\n",
    "\n",
    "This is the script to split the features in 3 different files in order to push to the repo"
   ],
   "id": "27ce084d7eb3589a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T20:03:35.261118Z",
     "start_time": "2024-04-26T20:03:29.403763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "def split_dict(filename, output_prefix):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    length = len(data['features'])\n",
    "    third_length = length // 3\n",
    "\n",
    "    split = [data['features'][0:third_length], data['features'][third_length:2*third_length], data['features'][2*third_length:length]]\n",
    "\n",
    "    for i in range(1,4):\n",
    "        with open(output_prefix + f'_{i}.pkl', 'wb') as f:\n",
    "            pickle.dump(split[i-1], f)\n",
    "\n",
    "split_dict('saved_features_an_multimodal/features_emg_spectrogram_train.pkl', 'saved_features_an_multimodal/features_emg_spectrogram_train_split')"
   ],
   "id": "1a3d0661e70becf0",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Decompress and join emg spectogram features\n",
    "\n",
    "This is the script to execute in order to obtain the joined features"
   ],
   "id": "40d10489a0c05d89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T20:14:19.797582Z",
     "start_time": "2024-04-26T20:14:13.449256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "def join_spectogram_feature(filename, output_name):\n",
    "    joined_features = {'features': []}\n",
    "    \n",
    "    for i in range(3):\n",
    "        with open(filename + f'_{i+1}.pkl', 'rb') as f:\n",
    "            joined_features['features'].extend(pickle.load(f))\n",
    "            \n",
    "    \n",
    "    with open(output_name, 'wb') as f:\n",
    "        pickle.dump(joined_features, f)\n",
    "        \n",
    "join_spectogram_feature('saved_features_an_multimodal/features_emg_spectrogram_train_split', \n",
    "                        'saved_features_an_multimodal/features_emg_spectrogram_train.pkl')"
   ],
   "id": "1379477bc51d351",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Model training",
   "id": "42e4ea77e6012e6d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### RGB model\n",
    "Indicate:\n",
    "- Dense sampling: to choose which features the model use for training\n",
    "- num frames per clip: to choose which features the model use for training\n",
    "- model: which model to use"
   ],
   "id": "8a1be341fa7282d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "python3 train_classifier.py name=train_model_rgb \\\n",
    "  config=configs/training_rgb.yaml \\\n",
    "  train.dense_sampling.RGB=True \\\n",
    "  train.num_frames_per_clip.RGB=25 \\\n",
    "  dataset.models.RGB=TRN_classifier"
   ],
   "id": "8f6ed977d2987778",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### EMG model\n",
    "\n",
    "Indicate:\n",
    "- spectogram_feat: To choose which kind of features the model is train on\n",
    "- model: according to the kind of modality \n",
    "    - spectogram_feat = True -> LeNet5\n",
    "    - spectogram_feat = False -> EMG_LSTM"
   ],
   "id": "3036d4d8faf5f887"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "python3 train_classifier_multimodal.py name=train_lstm_emg\\\n",
    "  config=configs/training_emg.yaml \\\n",
    "  train.spectogram_feat=False \\\n",
    "  models.EMG.model=EMG_LSTM"
   ],
   "id": "b8a11d4a5e82c02f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Multimodal models",
   "id": "70b5fda69a888d6b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Late fusion model",
   "id": "8dcb5014ce9682cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### Testing\n",
    "\n",
    "Indicate:\n",
    "- Dense sampling: to choose which features the model use for training\n",
    "- num frames per clip: to choose which features the model use for training\n",
    "- model: which model to use (both RGB and EMG)\n",
    "- spectogram_feat: To choose which kind of features the model is train on\n"
   ],
   "id": "382f7a6ddf5c03aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "python3 train_classifier_multimodal.py name=multimodal_late \\\n",
    "  config=configs/late_fusion_test.yaml \\\n",
    "  train.dense_sampling.RGB=True \\\n",
    "  train.num_frames_per_clip.RGB=25 \\\n",
    "  train.spectogram_feat=False \\\n",
    "  models.RGB.model=TRN_classifier \\\n",
    "  models.EMG.model=EMG_LSTM"
   ],
   "id": "320a343b4d4f7fe7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Midl level fusion model",
   "id": "7014e16224fe3ea5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### Mid level feature extraction\n",
    "\n",
    "Indicate: \n",
    "- Dense sampling: to choose which features the model use for training\n",
    "- num frames per clip: to choose which features the model use for training\n",
    "- split (train or test)\n",
    "- model: which model to use (both RGB and EMG)\n",
    "- spectogram_feat: To choose which kind of features the model is train on"
   ],
   "id": "1de3368a41064636"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T17:46:39.531907Z",
     "start_time": "2024-05-11T17:46:08.420199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "python3 save_feat_midlevel_multimodal.py name=midlevel_feat \\\n",
    "  config=configs/mid_level_extraction.yaml \\\n",
    "  split=train \\\n",
    "  save.dense_sampling.RGB=True \\\n",
    "  save.num_frames_per_clip.RGB=25 \\\n",
    "  save.spectogram_feat=False \\\n",
    "  models.RGB.model=Lstm_classifier \\\n",
    "  models.EMG.model=EMG_LSTM"
   ],
   "id": "cf5a78f161f7f822",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 19:46:10 LOG INFO Feature Extraction\n",
      "2024-05-11 19:46:10 LOG INFO Running with parameters: \n",
      "  action: save\n",
      "  name: midlevel_feat\n",
      "  modality: ['RGB', 'EMG']\n",
      "  total_batch: 128\n",
      "  batch_size: 32\n",
      "  gpus: None\n",
      "  wandb_name: None\n",
      "  resume_from:\n",
      "    RGB: saved_models/ActionNet/RGB_model/LSTM_dense_25/model_1/action-classifier_RGB_9.pth\n",
      "    EMG: saved_models/ActionNet/EMG_model/LSTM/model_1/action-classifier_EMG_9.pth\n",
      "  logname: save_S04-S04.log\n",
      "  models_dir: saved_models\n",
      "  aggregation: True\n",
      "  train:\n",
      "    num_iter: 5000\n",
      "    lr_steps: 3000\n",
      "    eval_freq: 50\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 5\n",
      "  test:\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 5\n",
      "  dataset:\n",
      "    annotations_path: an_multimodal_annotations\n",
      "    shift: S04-S04\n",
      "    workers: 4\n",
      "    stride: 2\n",
      "    resolution: 224\n",
      "    num_classes: 20\n",
      "    RGB:\n",
      "      data_path: saved_features_an_multimodal\n",
      "      tmpl: img_{:010d}.jpg\n",
      "      features_name: features_rgb\n",
      "    Event:\n",
      "      rgb4e: 6\n",
      "    EMG:\n",
      "      data_path: saved_features_an_multimodal\n",
      "      features_name: features_emg\n",
      "  models:\n",
      "    RGB:\n",
      "      model: Lstm_classifier\n",
      "      normalize: False\n",
      "      kwargs:\n",
      "      lr_steps: 3000\n",
      "      lr: 0.01\n",
      "      sgd_momentum: 0.9\n",
      "      weight_decay: 1e-07\n",
      "    EMG:\n",
      "      model: EMG_LSTM\n",
      "      normalize: False\n",
      "      kwargs:\n",
      "      lr_steps: 3000\n",
      "      lr: 0.01\n",
      "      sgd_momentum: 0.9\n",
      "      weight_decay: 1e-07\n",
      "  features_path: ['mid_level_features']\n",
      "  split: train\n",
      "  save:\n",
      "    num_iter: 5000\n",
      "    lr_steps: 3000\n",
      "    eval_freq: 50\n",
      "    num_clips: 5\n",
      "    spectogram_feat: False\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 25\n",
      "  config: configs/mid_level_extraction.yaml\n",
      "  experiment_dir: midlevel_feat/May11_19-46-08\n",
      "  log_dir: TEST_RESULTS/midlevel_feat\n",
      "  logfile: TEST_RESULTS/midlevel_feat/save_S04-S04.log\n",
      "2024-05-11 19:46:10 LOG INFO Instantiating models per modality\n",
      "2024-05-11 19:46:10 LOG INFO Lstm_classifier Net\tModality: RGB\n",
      "2024-05-11 19:46:10 LOG INFO EMG_LSTM Net\tModality: EMG\n",
      "2024-05-11 19:46:10 LOG INFO Restoring action-classifier for modality RGB from saved_models/ActionNet/RGB_model/LSTM_dense_25/model_1/action-classifier_RGB_9.pth\n",
      "2024-05-11 19:46:10 LOG INFO RGB-Model for action-classifier restored at iter 2250.0\n",
      "Best accuracy on val: 72.84 at iter 2150.0\n",
      "Last accuracy on val: 72.84\n",
      "Last loss: 0.00\n",
      "2024-05-11 19:46:10 LOG INFO Restoring action-classifier for modality EMG from saved_models/ActionNet/EMG_model/LSTM/model_1/action-classifier_EMG_9.pth\n",
      "2024-05-11 19:46:10 LOG INFO EMG-Model for action-classifier restored at iter 9900.0\n",
      "Best accuracy on val: 57.10 at iter 9450.0\n",
      "Last accuracy on val: 51.66\n",
      "Last loss: 0.00\n",
      "2024-05-11 19:46:10 LOG INFO Dataloader for S04-train with 735 samples generated\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###### Training\n",
    "\n",
    "Indicate: \n",
    "- Dense sampling: to choose which features the model use for training\n",
    "- num frames per clip: to choose which features the model use for training\n",
    "- model: which model to use (both RGB and EMG)\n",
    "- spectogram_feat: To choose which kind of features the model is train on"
   ],
   "id": "69f9598edbd932b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "\n",
    "python3 train_midlevel_classifier.py name=midlevel_classifier \\\n",
    "  config=configs/multimodal_midLevel_training.yaml \\\n",
    "  train.dense_sampling.RGB=True \\\n",
    "  train.num_frames_per_clip.RGB=25 \\\n",
    "  train.spectogram_feat=False \\\n",
    "  models.RGB.model=Lstm_classifier \\\n",
    "  models.EMG.model=EMG_LSTM"
   ],
   "id": "75331fccbedba134",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "91c4685cb03cf33b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
