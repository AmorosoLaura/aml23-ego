{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ffmpeg -i action-net/video/S04_video.mp4 -vf \"fps=30,scale=456:256\" -q:v 2 action-net/frames/S04_1/frame_%010d.jpg\n",
    "\n",
    "# save feat extracts, for the sampling mode indicated in the I3D file, the feature with 3 diffferent num frames per clip (5, 10, 25)\n",
    "\n",
    "python save_feat.py name=saved_features \\\n",
    "  config=configs/I3D_save_feat.yaml "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 17:23:12 LOG INFO Feature Extraction\n",
      "2024-04-09 17:23:12 LOG INFO Running with parameters: \n",
      "  action: save\n",
      "  name: features_action_net\n",
      "  modality: ['RGB']\n",
      "  total_batch: 128\n",
      "  batch_size: 32\n",
      "  gpus: None\n",
      "  wandb_name: None\n",
      "  resume_from: ./saved_models/I3D_SourceOnlyD1\n",
      "  logname: save_D1-S04.log\n",
      "  models_dir: models\n",
      "  aggregation: True\n",
      "  train:\n",
      "    num_iter: 5000\n",
      "    lr_steps: 3000\n",
      "    eval_freq: 50\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 5\n",
      "  test:\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 5\n",
      "  dataset:\n",
      "    annotations_path: action_net_annotations_training\n",
      "    shift: D1-S04\n",
      "    workers: 4\n",
      "    stride: 2\n",
      "    resolution: 224\n",
      "    num_classes: 8\n",
      "    RGB:\n",
      "      data_path: action-net/frames\n",
      "      tmpl: frame_{:010d}.jpg\n",
      "      features_name: features_action_net\n",
      "    Event:\n",
      "      rgb4e: 6\n",
      "  models:\n",
      "    RGB:\n",
      "      model: I3D\n",
      "      normalize: False\n",
      "      kwargs:\n",
      "      lr_steps: 3000\n",
      "      lr: 0.01\n",
      "      sgd_momentum: 0.9\n",
      "      weight_decay: 1e-07\n",
      "      dropout: 0.5\n",
      "      resolution: 224\n",
      "      weight_i3d_rgb: ./pretrained_i3d/rgb_imagenet.pt\n",
      "  split: train\n",
      "  save:\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 25\n",
      "  config: configs/I3D_save_feat_action_net.yaml\n",
      "  experiment_dir: features_action_net/Apr09_17-23-10\n",
      "  log_dir: TEST_RESULTS/features_action_net\n",
      "  logfile: TEST_RESULTS/features_action_net/save_D1-S04.log\n",
      "2024-04-09 17:23:12 LOG INFO Instantiating models per modality\n",
      "2024-04-09 17:23:12 LOG INFO I3D Net\tModality: RGB\n",
      "2024-04-09 17:23:12 LOG INFO Loading Kinetics weights I3D\n",
      "2024-04-09 17:23:12 LOG INFO  * Skipping Logits weight for 'logits.conv3d.weight'\n",
      "2024-04-09 17:23:12 LOG INFO  * Skipping Logits weight for 'logits.conv3d.bias'\n",
      "2024-04-09 17:23:12 LOG INFO Restoring action-classifier for modality RGB from saved_models/I3D_SourceOnlyD1/Oct25_22-38-50/action-classifier_RGB_9.pth\n",
      "2024-04-09 17:23:12 LOG INFO RGB-Model for action-classifier restored at iter 4850.0\n",
      "Best accuracy on val: 59.54 at iter 4000.0\n",
      "Last accuracy on val: 58.85\n",
      "Last loss: 0.00\n",
      "2024-04-09 17:23:12 LOG INFO Dataloader for S04-train with 735 samples generated\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 save_feat_action_net.py name=features_action_net \\\n",
    "  config=configs/I3D_save_feat_an.yaml \\\n",
    "  split=train \\\n",
    "  dataset.shift=D1-S04 \\\n",
    "  dataset.RGB.data_path=action-net/frames \\\n",
    "  dataset.annotations_path=action_net_annotations_training"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T15:44:26.350664Z",
     "start_time": "2024-04-09T15:23:10.000088Z"
    }
   },
   "id": "79e7a82f5923f8c",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 17:44:28 LOG INFO Feature Extraction\n",
      "2024-04-09 17:44:28 LOG INFO Running with parameters: \n",
      "  action: save\n",
      "  name: features_action_net\n",
      "  modality: ['RGB']\n",
      "  total_batch: 128\n",
      "  batch_size: 32\n",
      "  gpus: None\n",
      "  wandb_name: None\n",
      "  resume_from: ./saved_models/I3D_SourceOnlyD1\n",
      "  logname: save_D1-S04.log\n",
      "  models_dir: models\n",
      "  aggregation: True\n",
      "  train:\n",
      "    num_iter: 5000\n",
      "    lr_steps: 3000\n",
      "    eval_freq: 50\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 5\n",
      "  test:\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 5\n",
      "  dataset:\n",
      "    annotations_path: action_net_annotations_training\n",
      "    shift: D1-S04\n",
      "    workers: 4\n",
      "    stride: 2\n",
      "    resolution: 224\n",
      "    num_classes: 8\n",
      "    RGB:\n",
      "      data_path: action-net/frames\n",
      "      tmpl: frame_{:010d}.jpg\n",
      "      features_name: features_action_net\n",
      "    Event:\n",
      "      rgb4e: 6\n",
      "  models:\n",
      "    RGB:\n",
      "      model: I3D\n",
      "      normalize: False\n",
      "      kwargs:\n",
      "      lr_steps: 3000\n",
      "      lr: 0.01\n",
      "      sgd_momentum: 0.9\n",
      "      weight_decay: 1e-07\n",
      "      dropout: 0.5\n",
      "      resolution: 224\n",
      "      weight_i3d_rgb: ./pretrained_i3d/rgb_imagenet.pt\n",
      "  split: test\n",
      "  save:\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 25\n",
      "  config: configs/I3D_save_feat_action_net.yaml\n",
      "  experiment_dir: features_action_net/Apr09_17-44-26\n",
      "  log_dir: TEST_RESULTS/features_action_net\n",
      "  logfile: TEST_RESULTS/features_action_net/save_D1-S04.log\n",
      "2024-04-09 17:44:28 LOG INFO Instantiating models per modality\n",
      "2024-04-09 17:44:28 LOG INFO I3D Net\tModality: RGB\n",
      "2024-04-09 17:44:28 LOG INFO Loading Kinetics weights I3D\n",
      "2024-04-09 17:44:28 LOG INFO  * Skipping Logits weight for 'logits.conv3d.weight'\n",
      "2024-04-09 17:44:28 LOG INFO  * Skipping Logits weight for 'logits.conv3d.bias'\n",
      "2024-04-09 17:44:28 LOG INFO Restoring action-classifier for modality RGB from saved_models/I3D_SourceOnlyD1/Oct25_22-38-50/action-classifier_RGB_9.pth\n",
      "2024-04-09 17:44:28 LOG INFO RGB-Model for action-classifier restored at iter 4850.0\n",
      "Best accuracy on val: 59.54 at iter 4000.0\n",
      "Last accuracy on val: 58.85\n",
      "Last loss: 0.00\n",
      "2024-04-09 17:44:28 LOG INFO Dataloader for S04-test with 81 samples generated\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 save_feat_action_net.py name=features_action_net \\\n",
    "  config=configs/I3D_save_feat_an.yaml \\\n",
    "  split=test \\\n",
    "  dataset.shift=D1-S04 \\\n",
    "  dataset.RGB.data_path=action-net/frames \\\n",
    "  dataset.annotations_path=action_net_annotations_training"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T15:47:08.062760Z",
     "start_time": "2024-04-09T15:44:26.352292Z"
    }
   },
   "id": "1cfe14a1c20ba95",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 19:58:59 LOG INFO Running with parameters: \n",
      "  action: train\n",
      "  name: lstm_classifier_2layers_drop05_dense_5\n",
      "  modality: ['RGB']\n",
      "  total_batch: 128\n",
      "  batch_size: 32\n",
      "  gpus: None\n",
      "  wandb_name: None\n",
      "  resume_from: None\n",
      "  logname: None\n",
      "  models_dir: models\n",
      "  aggregation: True\n",
      "  train:\n",
      "    num_iter: 5000\n",
      "    lr_steps: 3000\n",
      "    eval_freq: 50\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 25\n",
      "  test:\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 5\n",
      "  dataset:\n",
      "    annotations_path: action_net_annotations_training\n",
      "    shift: S04-S04\n",
      "    workers: 4\n",
      "    stride: 2\n",
      "    resolution: 224\n",
      "    num_classes: 20\n",
      "    RGB:\n",
      "      data_path: saved_features_action_net\n",
      "      tmpl: img_{:010d}.jpg\n",
      "      features_name: features_action_net\n",
      "    Event:\n",
      "      rgb4e: 6\n",
      "  models:\n",
      "    RGB:\n",
      "      model: TRN_classifier\n",
      "      normalize: False\n",
      "      kwargs:\n",
      "      lr_steps: 3000\n",
      "      lr: 0.01\n",
      "      sgd_momentum: 0.9\n",
      "      weight_decay: 1e-07\n",
      "  config: configs/default.yaml\n",
      "  experiment_dir: lstm_classifier_2layers_drop05_dense_5/Apr10_19-58-57\n",
      "  log_dir: Experiment_logs/lstm_classifier_2layers_drop05_dense_5/Apr10_19-58-57\n",
      "  logfile: Experiment_logs/lstm_classifier_2layers_drop05_dense_5/Apr10_19-58-57/train.log\n",
      "2024-04-10 19:58:59 LOG INFO Instantiating models per modality\n",
      "2024-04-10 19:58:59 LOG INFO TRN_classifier Net\tModality: RGB\n",
      "2024-04-10 19:58:59 LOG INFO Dataloader for S04-train with 735 samples generated\n",
      "2024-04-10 19:58:59 LOG INFO Dataloader for S04-val with 81 samples generated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Scale Temporal Relation with classifier in use\n",
      "['5-frame relation', '4-frame relation', '3-frame relation', '2-frame relation']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 19:59:04 LOG INFO Iteration 0/20000 batch retrieved! Elapsed time = 0.0 m 0.200091 s\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 1/20000 batch retrieved! Elapsed time = 0.0 m 0.001598 s\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 2/20000 batch retrieved! Elapsed time = 0.0 m 0.000186 s\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 3/20000 batch retrieved! Elapsed time = 0.0 m 0.000152 s\n",
      "2024-04-10 19:59:05 LOG INFO [1/5000]\tlast Verb loss: 0.1550\tMean verb loss: 0.1542\tAcc@1: 0.00%\tAccMean@1: 2.34%\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 4/20000 batch retrieved! Elapsed time = 0.0 m 0.00013 s\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 5/20000 batch retrieved! Elapsed time = 0.0 m 0.000751 s\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 6/20000 batch retrieved! Elapsed time = 0.0 m 0.000196 s\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 7/20000 batch retrieved! Elapsed time = 0.0 m 0.00014 s\n",
      "2024-04-10 19:59:05 LOG INFO [2/5000]\tlast Verb loss: 0.1555\tMean verb loss: 0.1540\tAcc@1: 3.12%\tAccMean@1: 4.69%\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 8/20000 batch retrieved! Elapsed time = 0.0 m 9.6e-05 s\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 9/20000 batch retrieved! Elapsed time = 0.0 m 0.000342 s\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 10/20000 batch retrieved! Elapsed time = 0.0 m 0.000351 s\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 11/20000 batch retrieved! Elapsed time = 0.0 m 0.000305 s\n",
      "2024-04-10 19:59:05 LOG INFO [3/5000]\tlast Verb loss: 0.1520\tMean verb loss: 0.1518\tAcc@1: 3.12%\tAccMean@1: 4.69%\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 12/20000 batch retrieved! Elapsed time = 0.0 m 0.000323 s\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 13/20000 batch retrieved! Elapsed time = 0.0 m 0.000332 s\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 14/20000 batch retrieved! Elapsed time = 0.0 m 0.000372 s\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 15/20000 batch retrieved! Elapsed time = 0.0 m 0.000365 s\n",
      "2024-04-10 19:59:05 LOG INFO [4/5000]\tlast Verb loss: 0.1465\tMean verb loss: 0.1506\tAcc@1: 12.50%\tAccMean@1: 6.25%\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 16/20000 batch retrieved! Elapsed time = 0.0 m 0.000287 s\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 17/20000 batch retrieved! Elapsed time = 0.0 m 0.000291 s\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 18/20000 batch retrieved! Elapsed time = 0.0 m 0.000278 s\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 19/20000 batch retrieved! Elapsed time = 0.0 m 0.000322 s\n",
      "2024-04-10 19:59:05 LOG INFO [5/5000]\tlast Verb loss: 0.1503\tMean verb loss: 0.1467\tAcc@1: 6.25%\tAccMean@1: 7.03%\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 20/20000 batch retrieved! Elapsed time = 0.0 m 0.00024 s\n",
      "2024-04-10 19:59:05 LOG INFO Iteration 21/20000 batch retrieved! Elapsed time = 0.0 m 0.000236 s\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giorgiocacopardi/Documents/Magistrale/2anno/AdvancedMachineLearning/ExamProject/aml23-ego/train_classifier.py\", line 274, in <module>\n",
      "    main()\n",
      "  File \"/Users/giorgiocacopardi/Documents/Magistrale/2anno/AdvancedMachineLearning/ExamProject/aml23-ego/train_classifier.py\", line 89, in main\n",
      "    train(action_classifier, train_loader, val_loader, device, num_classes)\n",
      "  File \"/Users/giorgiocacopardi/Documents/Magistrale/2anno/AdvancedMachineLearning/ExamProject/aml23-ego/train_classifier.py\", line 139, in train\n",
      "    source_data, source_label = next(data_loader_source)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1318, in _next_data\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/connection.py\", line 947, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 train_classifier.py name=lstm_classifier_2layers_drop05_dense_5 \\\n",
    "  config=configs/default.yaml \\\n",
    "  models.RGB.model=TRN_classifier \\\n",
    "  train.dense_sampling.RGB=True \\\n",
    "  train.num_frames_per_clip.RGB=25"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T17:59:09.352600Z",
     "start_time": "2024-04-10T17:58:57.724958Z"
    }
   },
   "id": "ba757b05f0ceb888",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8fa87c7a0a24486e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
