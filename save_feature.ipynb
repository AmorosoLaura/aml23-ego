{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ffmpeg -i action-net/video/S04_video.mp4 -vf \"fps=30,scale=456:256\" -q:v 2 action-net/frames/S04_1/frame_%010d.jpg\n",
    "\n",
    "# save feat extracts, for the sampling mode indicated in the I3D file, the feature with 3 diffferent num frames per clip (5, 10, 25)\n",
    "\n",
    "python save_feat.py name=saved_features \\\n",
    "  config=configs/I3D_save_feat.yaml "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 19:14:04 LOG INFO Feature Extraction\n",
      "2024-04-16 19:14:04 LOG INFO Running with parameters: \n",
      "  action: save\n",
      "  name: features_rgb\n",
      "  modality: ['RGB']\n",
      "  total_batch: 128\n",
      "  batch_size: 32\n",
      "  gpus: None\n",
      "  wandb_name: None\n",
      "  resume_from: ./saved_models/I3D_SourceOnlyD1\n",
      "  logname: save_D1-S04.log\n",
      "  models_dir: models\n",
      "  aggregation: True\n",
      "  train:\n",
      "    num_iter: 5000\n",
      "    lr_steps: 3000\n",
      "    eval_freq: 50\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 5\n",
      "  test:\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 5\n",
      "  dataset:\n",
      "    annotations_path: action_net_annotations_training\n",
      "    shift: D1-S04\n",
      "    workers: 4\n",
      "    stride: 2\n",
      "    resolution: 224\n",
      "    num_classes: 8\n",
      "    RGB:\n",
      "      data_path: action-net/frames\n",
      "      tmpl: frame_{:010d}.jpg\n",
      "      features_name: features_action_net\n",
      "    Event:\n",
      "      rgb4e: 6\n",
      "  models:\n",
      "    RGB:\n",
      "      model: I3D\n",
      "      normalize: False\n",
      "      kwargs:\n",
      "      lr_steps: 3000\n",
      "      lr: 0.01\n",
      "      sgd_momentum: 0.9\n",
      "      weight_decay: 1e-07\n",
      "      dropout: 0.5\n",
      "      resolution: 224\n",
      "      weight_i3d_rgb: ./pretrained_i3d/rgb_imagenet.pt\n",
      "  split: train\n",
      "  save:\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 25\n",
      "  config: configs/I3D_save_feat_an.yaml\n",
      "  experiment_dir: features_rgb/Apr16_19-14-02\n",
      "  log_dir: TEST_RESULTS/features_rgb\n",
      "  logfile: TEST_RESULTS/features_rgb/save_D1-S04.log\n",
      "2024-04-16 19:14:04 LOG INFO Instantiating models per modality\n",
      "2024-04-16 19:14:04 LOG INFO I3D Net\tModality: RGB\n",
      "2024-04-16 19:14:04 LOG INFO Loading Kinetics weights I3D\n",
      "2024-04-16 19:14:04 LOG INFO  * Skipping Logits weight for 'logits.conv3d.weight'\n",
      "2024-04-16 19:14:04 LOG INFO  * Skipping Logits weight for 'logits.conv3d.bias'\n",
      "2024-04-16 19:14:04 LOG INFO ['action-classifier_RGB_9', 'action-classifier_RGB_7', 'action-classifier_RGB_6', 'action-classifier_RGB_8', 'action-classifier_RGB_4', 'action-classifier_RGB_5', 'action-classifier_RGB_3', 'action-classifier_RGB_2', 'action-classifier_RGB_1']\n",
      "2024-04-16 19:14:04 LOG INFO RGB\n",
      "2024-04-16 19:14:04 LOG INFO Dataloader for S04-train with 735 samples generated\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 save_feat_action_net.py name=features_rgb \\\n",
    "  config=configs/I3D_save_feat_an.yaml \\\n",
    "  split=train \\\n",
    "  dataset.shift=D1-S04 \\\n",
    "  dataset.RGB.data_path=action-net/frames \\\n",
    "  dataset.annotations_path=action_net_annotations_training"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T17:35:53.590707Z",
     "start_time": "2024-04-16T17:14:02.057960Z"
    }
   },
   "id": "79e7a82f5923f8c",
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 19:38:58 LOG INFO Feature Extraction\n",
      "2024-04-16 19:38:58 LOG INFO Running with parameters: \n",
      "  action: save\n",
      "  name: features_rgb\n",
      "  modality: ['RGB']\n",
      "  total_batch: 128\n",
      "  batch_size: 32\n",
      "  gpus: None\n",
      "  wandb_name: None\n",
      "  resume_from: ./saved_models/I3D_SourceOnlyD1\n",
      "  logname: save_D1-S04.log\n",
      "  models_dir: models\n",
      "  aggregation: True\n",
      "  train:\n",
      "    num_iter: 5000\n",
      "    lr_steps: 3000\n",
      "    eval_freq: 50\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 5\n",
      "  test:\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 5\n",
      "  dataset:\n",
      "    annotations_path: action_net_annotations_training\n",
      "    shift: D1-S04\n",
      "    workers: 4\n",
      "    stride: 2\n",
      "    resolution: 224\n",
      "    num_classes: 8\n",
      "    RGB:\n",
      "      data_path: action-net/frames\n",
      "      tmpl: frame_{:010d}.jpg\n",
      "      features_name: features_action_net\n",
      "    Event:\n",
      "      rgb4e: 6\n",
      "  models:\n",
      "    RGB:\n",
      "      model: I3D\n",
      "      normalize: False\n",
      "      kwargs:\n",
      "      lr_steps: 3000\n",
      "      lr: 0.01\n",
      "      sgd_momentum: 0.9\n",
      "      weight_decay: 1e-07\n",
      "      dropout: 0.5\n",
      "      resolution: 224\n",
      "      weight_i3d_rgb: ./pretrained_i3d/rgb_imagenet.pt\n",
      "  split: test\n",
      "  save:\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 25\n",
      "  config: configs/I3D_save_feat_an.yaml\n",
      "  experiment_dir: features_rgb/Apr16_19-38-57\n",
      "  log_dir: TEST_RESULTS/features_rgb\n",
      "  logfile: TEST_RESULTS/features_rgb/save_D1-S04.log\n",
      "2024-04-16 19:38:58 LOG INFO Instantiating models per modality\n",
      "2024-04-16 19:38:58 LOG INFO I3D Net\tModality: RGB\n",
      "2024-04-16 19:38:58 LOG INFO Loading Kinetics weights I3D\n",
      "2024-04-16 19:38:58 LOG INFO  * Skipping Logits weight for 'logits.conv3d.weight'\n",
      "2024-04-16 19:38:58 LOG INFO  * Skipping Logits weight for 'logits.conv3d.bias'\n",
      "2024-04-16 19:38:58 LOG INFO ['action-classifier_RGB_9', 'action-classifier_RGB_7', 'action-classifier_RGB_6', 'action-classifier_RGB_8', 'action-classifier_RGB_4', 'action-classifier_RGB_5', 'action-classifier_RGB_3', 'action-classifier_RGB_2', 'action-classifier_RGB_1']\n",
      "2024-04-16 19:38:58 LOG INFO RGB\n",
      "2024-04-16 19:38:58 LOG INFO Dataloader for S04-test with 81 samples generated\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 save_feat_action_net.py name=features_rgb \\\n",
    "  config=configs/I3D_save_feat_an.yaml \\\n",
    "  split=test \\\n",
    "  dataset.shift=D1-S04 \\\n",
    "  dataset.RGB.data_path=action-net/frames \\\n",
    "  dataset.annotations_path=action_net_annotations_training"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T17:41:34.133150Z",
     "start_time": "2024-04-16T17:38:56.862001Z"
    }
   },
   "id": "1cfe14a1c20ba95",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 18:05:06 LOG INFO Running with parameters: \n",
      "  action: train\n",
      "  name: multimodal\n",
      "  modality: ['RGB', 'EMG']\n",
      "  total_batch: 128\n",
      "  batch_size: 32\n",
      "  gpus: None\n",
      "  wandb_name: None\n",
      "  resume_from:\n",
      "    RGB: None\n",
      "    EMG: ./saved_models/EMG_lstm\n",
      "  logname: None\n",
      "  models_dir: models\n",
      "  aggregation: True\n",
      "  train:\n",
      "    num_iter: 5000\n",
      "    lr_steps: 3000\n",
      "    eval_freq: 50\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 25\n",
      "  test:\n",
      "    num_clips: 5\n",
      "    dense_sampling:\n",
      "      RGB: True\n",
      "    num_frames_per_clip:\n",
      "      RGB: 5\n",
      "  dataset:\n",
      "    annotations_path: an_multimodal_annotations\n",
      "    shift: S04-S04\n",
      "    workers: 4\n",
      "    stride: 2\n",
      "    resolution: 224\n",
      "    num_classes: 20\n",
      "    RGB:\n",
      "      data_path: saved_features_an_multimodal\n",
      "      tmpl: img_{:010d}.jpg\n",
      "      features_name: features_rgb\n",
      "    Event:\n",
      "      rgb4e: 6\n",
      "    EMG:\n",
      "      data_path: saved_features_an_multimodal\n",
      "      features_name: features_emg\n",
      "  models:\n",
      "    RGB:\n",
      "      model: TRN_classifier\n",
      "      normalize: False\n",
      "      kwargs:\n",
      "      lr_steps: 3000\n",
      "      lr: 0.01\n",
      "      sgd_momentum: 0.9\n",
      "      weight_decay: 1e-07\n",
      "    EMG:\n",
      "      model: EMG_LSTM\n",
      "      normalize: False\n",
      "      kwargs:\n",
      "      lr_steps: 3000\n",
      "      lr: 0.01\n",
      "      sgd_momentum: 0.9\n",
      "      weight_decay: 1e-07\n",
      "  config: configs/multimodal_an.yaml\n",
      "  experiment_dir: multimodal/Apr16_18-05-04\n",
      "  log_dir: Experiment_logs/multimodal/Apr16_18-05-04\n",
      "  logfile: Experiment_logs/multimodal/Apr16_18-05-04/train.log\n",
      "2024-04-16 18:05:06 LOG INFO Instantiating models per modality\n",
      "2024-04-16 18:05:06 LOG INFO TRN_classifier Net\tModality: RGB\n",
      "2024-04-16 18:05:07 LOG INFO EMG_LSTM Net\tModality: EMG\n",
      "2024-04-16 18:05:07 LOG INFO ['action-classifier_EMG_9', 'action-classifier_EMG_8', 'action-classifier_EMG_7', 'action-classifier_EMG_6', 'action-classifier_EMG_5', 'action-classifier_EMG_4', 'action-classifier_EMG_2', 'action-classifier_EMG_1']\n",
      "2024-04-16 18:05:07 LOG INFO RGB\n",
      "2024-04-16 18:05:07 LOG INFO EMG\n",
      "2024-04-16 18:05:07 LOG INFO Restoring action-classifier for modality EMG from saved_models/EMG_lstm/Apr15_16-42-09/action-classifier_EMG_9.pth\n",
      "2024-04-16 18:05:07 LOG INFO EMG-Model for action-classifier restored at iter 19800.0\n",
      "Best accuracy on val: 62.72 at iter 7350.0\n",
      "Last accuracy on val: 58.59\n",
      "Last loss: 0.00\n",
      "2024-04-16 18:05:07 LOG INFO Dataloader for S04-train with 735 samples generated\n",
      "2024-04-16 18:05:07 LOG INFO MODEL FEATURES: Empty DataFrame\n",
      "Columns: [features_RGB, features_EMG, uid, participant_id, video_id, description, verb_class]\n",
      "Index: []\n",
      "2024-04-16 18:05:07 LOG INFO Dataloader for S04-val with 81 samples generated\n",
      "2024-04-16 18:05:07 LOG INFO MODEL FEATURES:    uid  ... verb_class\n",
      "0  208  ...         18\n",
      "1  212  ...         18\n",
      "2  225  ...          6\n",
      "3  234  ...          6\n",
      "4  248  ...          8\n",
      "5  276  ...         15\n",
      "\n",
      "[6 rows x 7 columns]\n",
      "2024-04-16 18:05:07 LOG INFO GLOBBBB 20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Scale Temporal Relation with classifier in use\n",
      "['5-frame relation', '4-frame relation', '3-frame relation', '2-frame relation']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 18:05:12 LOG INFO SAMPLE ROW: Empty DataFrame\n",
      "Columns: [features_RGB, features_EMG, uid, participant_id, video_id, description, verb_class]\n",
      "Index: []\n",
      "2024-04-16 18:05:12 LOG INFO SAMPLE ROW: Empty DataFrame\n",
      "Columns: [features_RGB, features_EMG, uid, participant_id, video_id, description, verb_class]\n",
      "Index: []\n",
      "2024-04-16 18:05:12 LOG INFO SAMPLE ROW: Empty DataFrame\n",
      "Columns: [features_RGB, features_EMG, uid, participant_id, video_id, description, verb_class]\n",
      "Index: []\n",
      "2024-04-16 18:05:12 LOG INFO iterations 0\n",
      "2024-04-16 18:05:12 LOG INFO SAMPLE ROW: Empty DataFrame\n",
      "Columns: [features_RGB, features_EMG, uid, participant_id, video_id, description, verb_class]\n",
      "Index: []\n",
      "2024-04-16 18:05:12 LOG INFO SAMPLE ROW: Empty DataFrame\n",
      "Columns: [features_RGB, features_EMG, uid, participant_id, video_id, description, verb_class]\n",
      "Index: []\n",
      "2024-04-16 18:05:12 LOG INFO SAMPLE ROW: Empty DataFrame\n",
      "Columns: [features_RGB, features_EMG, uid, participant_id, video_id, description, verb_class]\n",
      "Index: []\n",
      "2024-04-16 18:05:12 LOG INFO SAMPLE ROW: Empty DataFrame\n",
      "Columns: [features_RGB, features_EMG, uid, participant_id, video_id, description, verb_class]\n",
      "Index: []\n",
      "2024-04-16 18:05:12 LOG ERROR Uncaught exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giorgiocacopardi/Documents/Magistrale/2anno/AdvancedMachineLearning/ExamProject/aml23-ego/train_classifier_multimodal.py\", line 250, in <module>\n",
      "    main()\n",
      "  File \"/Users/giorgiocacopardi/Documents/Magistrale/2anno/AdvancedMachineLearning/ExamProject/aml23-ego/train_classifier_multimodal.py\", line 92, in main\n",
      "    train(action_classifier, train_loader, val_loader, device, num_classes)\n",
      "  File \"/Users/giorgiocacopardi/Documents/Magistrale/2anno/AdvancedMachineLearning/ExamProject/aml23-ego/train_classifier_multimodal.py\", line 136, in train\n",
      "    source_data, source_label = next(data_loader_source)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1346, in _next_data\n",
      "    return self._process_data(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1372, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/torch/_utils.py\", line 722, in reraise\n",
      "    raise exception\n",
      "AssertionError: Caught AssertionError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"/Users/giorgiocacopardi/Documents/Magistrale/2anno/AdvancedMachineLearning/ExamProject/aml23-ego/utils/loader_action_net.py\", line 80, in __getitem__\n",
      "    assert len(sample_row) == 1\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'\\npython3 train_classifier_multimodal.py name=multimodal \\\\\\n  config=configs/multimodal_an.yaml \\\\\\n  train.dense_sampling.RGB=True \\\\\\n  train.num_frames_per_clip.RGB=25\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mCalledProcessError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[64], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_cell_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbash\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43mpython3 train_classifier_multimodal.py name=multimodal \u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m  config=configs/multimodal_an.yaml \u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m  train.dense_sampling.RGB=True \u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m  train.num_frames_per_clip.RGB=25\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2493\u001B[0m, in \u001B[0;36mInteractiveShell.run_cell_magic\u001B[0;34m(self, magic_name, line, cell)\u001B[0m\n\u001B[1;32m   2491\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[1;32m   2492\u001B[0m     args \u001B[38;5;241m=\u001B[39m (magic_arg_s, cell)\n\u001B[0;32m-> 2493\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2495\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[1;32m   2496\u001B[0m \u001B[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001B[39;00m\n\u001B[1;32m   2497\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[1;32m   2498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/IPython/core/magics/script.py:154\u001B[0m, in \u001B[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001B[0;34m(line, cell)\u001B[0m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    153\u001B[0m     line \u001B[38;5;241m=\u001B[39m script\n\u001B[0;32m--> 154\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshebang\u001B[49m\u001B[43m(\u001B[49m\u001B[43mline\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcell\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/IPython/core/magics/script.py:314\u001B[0m, in \u001B[0;36mScriptMagics.shebang\u001B[0;34m(self, line, cell)\u001B[0m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39mraise_error \u001B[38;5;129;01mand\u001B[39;00m p\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    310\u001B[0m     \u001B[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001B[39;00m\n\u001B[1;32m    311\u001B[0m     \u001B[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001B[39;00m\n\u001B[1;32m    312\u001B[0m     \u001B[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001B[39;00m\n\u001B[1;32m    313\u001B[0m     rc \u001B[38;5;241m=\u001B[39m p\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m9\u001B[39m\n\u001B[0;32m--> 314\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CalledProcessError(rc, cell)\n",
      "\u001B[0;31mCalledProcessError\u001B[0m: Command 'b'\\npython3 train_classifier_multimodal.py name=multimodal \\\\\\n  config=configs/multimodal_an.yaml \\\\\\n  train.dense_sampling.RGB=True \\\\\\n  train.num_frames_per_clip.RGB=25\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 train_classifier_multimodal.py name=multimodal \\\n",
    "  config=configs/multimodal_an.yaml \\\n",
    "  train.dense_sampling.RGB=True \\\n",
    "  train.num_frames_per_clip.RGB=25"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T16:05:12.383981Z",
     "start_time": "2024-04-16T16:05:04.633865Z"
    }
   },
   "id": "ba757b05f0ceb888",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8fa87c7a0a24486e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
