{
 "cells": [
  {
   "cell_type": "code",
   "id": "f7288622a8212497",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T08:00:58.302898Z",
     "start_time": "2024-05-22T08:00:57.691168Z"
    }
   },
   "source": [
    "import pickle\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "activities_to_classify = {\n",
    "        'Get/replace items from refrigerator/cabinets/drawers': 0,\n",
    "        'Peel a cucumber': 1,\n",
    "        'Clear cutting board': 2,\n",
    "        'Slice a cucumber': 3,\n",
    "        'Peel a potato': 4,\n",
    "        'Slice a potato': 5,\n",
    "        'Slice bread': 6,\n",
    "        'Spread almond butter on a bread slice': 7,\n",
    "        'Spread jelly on a bread slice': 8,\n",
    "        'Open/close a jar of almond butter': 9,\n",
    "        'Pour water from a pitcher into a glass': 10,\n",
    "        'Clean a plate with a sponge': 11,\n",
    "        'Clean a plate with a towel': 12,\n",
    "        'Clean a pan with a sponge': 13,\n",
    "        'Clean a pan with a towel': 14,\n",
    "        'Get items from cabinets: 3 each large/small plates, bowls, mugs, glasses, sets of utensils': 15,\n",
    "        'Set table: 3 each large/small plates, bowls, mugs, glasses, sets of utensils': 16,\n",
    "        'Stack on table: 3 each large/small plates, bowls': 17,\n",
    "        'Load dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils': 18,\n",
    "        'Unload dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils': 19,\n",
    "}\n",
    "\n",
    "FPS = 30\n",
    "ACTION_LENGTH = 5\n",
    "\n",
    "def augmentation(data_frame):\n",
    "    augmented_data = []\n",
    "\n",
    "    for _, row in data_frame.iterrows():\n",
    "        start_frame = row['start_frame']\n",
    "        stop_frame = row['stop_frame']\n",
    "        interval_size = FPS * ACTION_LENGTH \n",
    "\n",
    "        num_intervals = math.ceil((stop_frame - start_frame + 1) / interval_size)\n",
    "\n",
    "        for i in range(num_intervals):\n",
    "            new_start = start_frame + i * interval_size\n",
    "            new_stop = min(new_start + interval_size - 1, stop_frame)  \n",
    "            new_row = row.copy()\n",
    "            new_row['start_frame'] = new_start\n",
    "            new_row['stop_frame'] = new_stop\n",
    "            new_row['start_timestamp'] = new_start/FPS\n",
    "            new_row['stop_timestamp'] = new_stop/FPS\n",
    "            augmented_data.append(new_row)\n",
    "\n",
    "    augmented_dataframe = pd.DataFrame(augmented_data, columns=data_frame.columns)\n",
    "    augmented_dataframe.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return augmented_dataframe\n",
    "\n",
    "def create_annotations_file(timestamp_file, annotations_file, type='train'):\n",
    "\n",
    "    timestamps = pd.read_pickle(timestamp_file)\n",
    "    timestamps = timestamps.drop(\n",
    "        ['myo_left_timestamps', 'myo_right_timestamps', 'myo_left_readings', 'myo_right_readings'], axis=1)\n",
    "    timestamps = timestamps.reset_index()\n",
    "\n",
    "    start_timestamp = timestamps['start'].iloc[0]\n",
    "    timestamps['start_frame'] = ((timestamps['start'] - start_timestamp) * FPS).astype(int)\n",
    "    timestamps['stop_frame'] = ((timestamps['stop'] - start_timestamp) * FPS).astype(int)\n",
    "    \n",
    "    annotations = pd.read_pickle(annotations_file)\n",
    "    annotations = annotations[annotations['file'] == 'S04_1.pkl']\n",
    "    annotations = annotations.drop(['labels'], axis=1)\n",
    "    \n",
    "    complete_labels = pd.merge(timestamps, annotations, on='index', how='inner')\n",
    "    \n",
    "    complete_labels['uid'] = complete_labels['index']\n",
    "    complete_labels['participant_id'] = 'S04'\n",
    "    complete_labels['video_id'] = 'S04_1'\n",
    "    complete_labels['verb'] = complete_labels['description_x']\n",
    "    complete_labels['narration'] = complete_labels['description_x']\n",
    "    complete_labels['verb_class'] = complete_labels['verb'].map(activities_to_classify)\n",
    "\n",
    "    complete_labels = complete_labels[\n",
    "        ['uid', 'participant_id', 'video_id', 'narration', 'start', 'stop', 'start_frame',\n",
    "         'stop_frame', 'verb', 'verb_class']]\n",
    "    \n",
    "    complete_labels['type'] = type\n",
    "    \n",
    "    return complete_labels\n",
    "\n",
    "def change_uid_to_emg(emg_data, split):\n",
    "    emg_data = pd.read_pickle(emg_data)\n",
    "    emg_data['uid'] = emg_data.reset_index().index + 1\n",
    "    emg_data.to_pickle(f'new_emg_data_{split}.pkl')    \n",
    "\n",
    "\n",
    "def take_S04_annotations_RGB(timestamps, emg_data, type):\n",
    "    \n",
    "    calibration_val = pd.read_pickle(timestamps)['start'].iloc[0]\n",
    "\n",
    "    emg_data = pd.read_pickle(emg_data)\n",
    "    \n",
    "    emg_data = emg_data[emg_data['file'] == 'S04_1.pkl']\n",
    "    \n",
    "    emg_data = emg_data.rename(columns={'file': 'video_id', 'description': 'narration', 'description_class': 'verb_class'})\n",
    "    emg_data['participant_id'] = 'S04'\n",
    "    emg_data['video_id'] = 'S04_1'\n",
    "    emg_data['start_frame'] = ((emg_data['start'] - calibration_val) * FPS).astype(int)\n",
    "    emg_data['stop_frame'] = ((emg_data['stop'] - calibration_val) * FPS).astype(int)\n",
    "    emg_data['verb'] = emg_data['narration']\n",
    "    emg_data = emg_data.drop(['emg_data'], axis = 1)\n",
    "    emg_data = emg_data[\n",
    "        ['uid', 'participant_id', 'video_id', 'narration', 'start', 'stop', 'start_frame',\n",
    "         'stop_frame', 'verb', 'verb_class']]\n",
    "    \n",
    "    emg_data.to_pickle(f'an_annotations_rgb/S04_trial_{type}.pkl')    \n",
    "\n",
    "def create_reduced_annotations(train_annotations, test_annotations):\n",
    "    \n",
    "    combined_df = pd.concat([train_annotations, test_annotations], ignore_index=True)\n",
    "    \n",
    "    combined_df = combined_df.sample(frac=1)\n",
    "\n",
    "    combined_df.reset_index(inplace=True)\n",
    "    combined_df['uid'] = combined_df.index\n",
    "    \n",
    "    train_df_final = combined_df[combined_df['type'] == 'train']\n",
    "    test_df_final = combined_df[combined_df['type'] == 'test']\n",
    "    \n",
    "    train_df_final = train_df_final.drop(['type'], axis=1)\n",
    "    test_df_final = test_df_final.drop(['type'], axis=1)\n",
    "\n",
    "    train_df_final.to_pickle(f\"an_annotations_rgb/S04_train.pkl\")    \n",
    "    test_df_final.to_pickle(f\"an_annotations_rgb/S04_test.pkl\")   \n",
    "    \n",
    "def create_multimodal_annotations(full_data, split, spectogram):\n",
    "    \n",
    "    full_data = pd.read_pickle(full_data)\n",
    "    full_data = full_data[full_data['file'] == 'S04_1.pkl']\n",
    "    full_data = full_data.rename(columns={'description_class': 'verb_class'})\n",
    "    full_data['participant_id'] = 'S04'\n",
    "    full_data['video_id'] = 'S04_1'\n",
    "    \n",
    "    create_emg_features(deepcopy(full_data), split, spectogram)\n",
    "    \n",
    "    final_annotations = full_data[\n",
    "        ['uid', 'participant_id', 'video_id', 'description', 'verb_class']]\n",
    "    \n",
    "    final_annotations.to_pickle(f\"an_multimodal_annotations/S04_{split}.pkl\")   \n",
    "\n",
    "def create_emg_features(full_data, split, spectogram):\n",
    "    \n",
    "    full_data = full_data[full_data['file'] == 'S04_1.pkl']\n",
    "    full_data = full_data.rename(columns={'emg_data': 'features_EMG'})\n",
    "    \n",
    "    emg_features = full_data[\n",
    "        ['uid', 'features_EMG']]\n",
    "    emg_features = emg_features.to_dict('list')\n",
    "    emg_features = {'features': emg_features}\n",
    "\n",
    "    features_name = f'saved_features_an_multimodal/features_emg_spectogram_S04_{split}.pkl' if spectogram \\\n",
    "        else f'saved_features_an_multimodal/features_emg_S04_{split}.pkl'\n",
    "      \n",
    "    with open(features_name, 'wb') as f:\n",
    "        pickle.dump(emg_features, f)\n",
    "          \n",
    "def create_emg_spec_features(full_data, split, spectrogram):\n",
    "    \n",
    "    full_data = pd.read_pickle(full_data)\n",
    "    \n",
    "    full_data = full_data.rename(columns={'spectrogram': 'features_EMG_spectrogram'})\n",
    "    \n",
    "    print(split)\n",
    "    emg_features = full_data[\n",
    "        ['uid', 'features_EMG_spectrogram']]\n",
    "    emg_features= emg_features.to_dict(orient='index')\n",
    "    emg_features = {'features': list(emg_features.values())}\n",
    "    # Creazione del dizionario desiderato\n",
    "\n",
    "    features_name = f'saved_features_an_multimodal/features_emg_80fs_spectrogram_allData_{split}.pkl' if spectrogram \\\n",
    "        else f'saved_features_an_multimodal/features_emg_80fs_allData_{split}.pkl'\n",
    "      \n",
    "    with open(features_name, 'wb') as f:\n",
    "        pickle.dump(emg_features, f)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "c12888eac96f2059",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T08:03:07.536179Z",
     "start_time": "2024-05-22T08:03:07.458672Z"
    }
   },
   "source": [
    "take_S04_annotations_RGB(timestamps='action-net/S04_1.pkl', emg_data='an_multimodal_annotations/emg_trial_test.pkl', type='test')\n",
    "take_S04_annotations_RGB(timestamps='action-net/S04_1.pkl', emg_data='an_multimodal_annotations/emg_trial_train.pkl', type='train')"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8375367fedd5dee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T18:46:23.276885Z",
     "start_time": "2024-04-16T18:46:23.217221Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_multimodal_annotations(full_data=\"new_emg_data_train.pkl\", split='train', spectogram=False)\n",
    "create_multimodal_annotations(full_data=\"new_emg_data_test.pkl\", split='test', spectogram=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b9923",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_emg_features(full_data=\"new_emg_data_train.pkl\", split='train')\n",
    "create_emg_features(full_data=\"new_emg_data_test.pkl\", split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1d13b1a4f66adc26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T17:08:55.028127Z",
     "start_time": "2024-04-16T17:08:54.959225Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "train\n"
     ]
    }
   ],
   "source": [
    "create_emg_spec_features(full_data=\"C:/Users/Laura/Desktop/Universita/Polito/Advanced Machine Learning/aml23-ego/EMG_data/emg_spectrogram_80fs_test.pkl\", spectrogram=True, split='test')\n",
    "create_emg_spec_features(full_data=\"C:/Users/Laura/Desktop/Universita/Polito/Advanced Machine Learning/aml23-ego/EMG_data/emg_spectrogram_80fs_train.pkl\", spectrogram=True, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f592f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "with open('new_emg_data_top_test.pkl', 'rb') as f_pickle:\n",
    "      dati=pickle.load(f_pickle)\n",
    "      print(dati)\n",
    "      df=pd.DataFrame(dati)\n",
    "      \n",
    "      # print(df.to_string(index=False, justify='right'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce3691",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle(\"C:/Users/Laura/Desktop/Universita/Polito/Advanced Machine Learning/aml23-ego/EMG_data/emg_spectrogram_80fs_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "dd925c1a72951cb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T08:01:59.669778Z",
     "start_time": "2024-05-22T08:01:59.659802Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "data2 = pd.read_pickle('an_multimodal_annotations/.pkl')\n",
    "\n",
    "data2"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     uid                                       description  verb_class\n",
       "0    474                                       Slice bread           6\n",
       "1    309                                    Slice a potato           5\n",
       "2    715  Stack on table: 3 each large/small plates, bowls          17\n",
       "3    679                                       Slice bread           6\n",
       "4    466                                    Slice a potato           5\n",
       "..   ...                                               ...         ...\n",
       "897  870                     Spread jelly on a bread slice           8\n",
       "898  526                     Spread jelly on a bread slice           8\n",
       "899  279                                   Peel a cucumber           1\n",
       "900   78                                       Slice bread           6\n",
       "901  636                                    Slice a potato           5\n",
       "\n",
       "[902 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>description</th>\n",
       "      <th>verb_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>474</td>\n",
       "      <td>Slice bread</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>309</td>\n",
       "      <td>Slice a potato</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>715</td>\n",
       "      <td>Stack on table: 3 each large/small plates, bowls</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>679</td>\n",
       "      <td>Slice bread</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>466</td>\n",
       "      <td>Slice a potato</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>870</td>\n",
       "      <td>Spread jelly on a bread slice</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>526</td>\n",
       "      <td>Spread jelly on a bread slice</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>279</td>\n",
       "      <td>Peel a cucumber</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>78</td>\n",
       "      <td>Slice bread</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>636</td>\n",
       "      <td>Slice a potato</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>902 rows Ã— 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8535c07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame(pd.read_pickle('C:/Users/Laura/Desktop/Universita/Polito/Advanced Machine Learning/aml23-ego/EMG_data/emg_spectrogram_80fs_test.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
