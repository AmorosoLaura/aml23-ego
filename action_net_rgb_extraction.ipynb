{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "def fill_missing_intervals(df):\n",
    "    df = df.sort_values(by='start_frame')\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    for i in range(len(df) - 1):\n",
    "        current_row = df.loc[i]\n",
    "        next_row = df.loc[i + 1]\n",
    "\n",
    "        missing_interval_start = current_row['stop_frame'] + 1\n",
    "        missing_interval_end = next_row['start_frame'] - 1\n",
    "\n",
    "        if missing_interval_start <= missing_interval_end:\n",
    "            new_row = pd.DataFrame({\n",
    "                'uid': 90,\n",
    "                'participant_id': 'S04',\n",
    "                'video_id': 'S04_01',\n",
    "                'narration': 'None',\n",
    "                'verb': 'None',\n",
    "                'verb_class': 0,\n",
    "                'start_frame': [missing_interval_start],\n",
    "                'stop_frame': [missing_interval_end],\n",
    "                'start_timestamp': [missing_interval_start / 22],\n",
    "                'stop_timestamp': [missing_interval_end / 22],\n",
    "            })\n",
    "            dfs.append(new_row)\n",
    "\n",
    "    if dfs:\n",
    "        filled_df = pd.concat([df] + dfs, ignore_index=True)\n",
    "    else:\n",
    "        filled_df = df.copy()\n",
    "\n",
    "    return filled_df\n",
    "\n",
    "def split_rows(data_frame):\n",
    "    augmented_data = []\n",
    "\n",
    "    for _, row in data_frame.iterrows():\n",
    "        start_frame = row['start_frame']\n",
    "        stop_frame = row['stop_frame']\n",
    "        interval_size = 110  \n",
    "\n",
    "        num_intervals = math.ceil((stop_frame - start_frame + 1) / interval_size)\n",
    "\n",
    "        for i in range(num_intervals):\n",
    "            new_start = start_frame + i * interval_size\n",
    "            new_stop = min(new_start + interval_size - 1, stop_frame)  \n",
    "            new_row = row.copy()\n",
    "            new_row['start_frame'] = new_start\n",
    "            new_row['stop_frame'] = new_stop\n",
    "            new_row['start_timestamp'] = new_start/22\n",
    "            new_row['stop_timestamp'] = new_stop/22\n",
    "            augmented_data.append(new_row)\n",
    "\n",
    "    augmented_dataframe = pd.DataFrame(augmented_data, columns=data_frame.columns)\n",
    "    augmented_dataframe.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return augmented_dataframe\n",
    "\n",
    "def extend_video_id(df):\n",
    "    extended_data = []\n",
    "    num_extensions = 4\n",
    "\n",
    "    for _ in range(num_extensions):\n",
    "        extended_data.append(df.copy())\n",
    "\n",
    "    for i in range(num_extensions):\n",
    "        extended_data[i]['video_id'] = f'S04_0{i + 2}' \n",
    "\n",
    "    result = pd.concat([df] + extended_data, ignore_index=True)\n",
    "    return result\n",
    "\n",
    "\n",
    "def create_annotations_file(timestamp_file, annotations_file_test, annotations_file_train):\n",
    "    import pandas as pd\n",
    "\n",
    "    activities_to_classify = [\n",
    "        'Get/replace items from refrigerator/cabinets/drawers',\n",
    "        'Peel a cucumber',\n",
    "        'Clear cutting board',\n",
    "        'Slice a cucumber',\n",
    "        'Peel a potato',\n",
    "        'Slice a potato',\n",
    "        'Slice bread',\n",
    "        'Spread almond butter on a bread slice',\n",
    "        'Spread jelly on a bread slice',\n",
    "        'Open/close a jar of almond butter',\n",
    "        'Pour water from a pitcher into a glass',\n",
    "        'Clean a plate with a sponge',\n",
    "        'Clean a plate with a towel',\n",
    "        'Clean a pan with a sponge',\n",
    "        'Clean a pan with a towel',\n",
    "        'Get items from cabinets: 3 each large/small plates, bowls, mugs, glasses, sets of utensils',\n",
    "        'Set table: 3 each large/small plates, bowls, mugs, glasses, sets of utensils',\n",
    "        'Stack on table: 3 each large/small plates, bowls',\n",
    "        'Load dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils',\n",
    "        'Unload dishwasher: 3 each large/small plates, bowls, mugs, glasses, sets of utensils',\n",
    "    ]\n",
    "\n",
    "    video_fps = 22\n",
    "\n",
    "    timestamps = pd.read_pickle(timestamp_file)\n",
    "    timestamps = timestamps.drop(\n",
    "        ['myo_left_timestamps', 'myo_right_timestamps', 'myo_left_readings', 'myo_right_readings'], axis=1)\n",
    "    timestamps = timestamps.reset_index()\n",
    "\n",
    "    start_timestamp = timestamps['start'].iloc[0]\n",
    "    timestamps['start_timestamp'] = timestamps['start'] - start_timestamp\n",
    "    timestamps['stop_timestamp'] = timestamps['stop'] - start_timestamp\n",
    "    timestamps['start_frame'] = (timestamps['start_timestamp'] * video_fps).astype(int)\n",
    "    timestamps['stop_frame'] = (timestamps['stop_timestamp'] * video_fps).astype(int)\n",
    "    \n",
    "    data_frame_train = pd.read_pickle(annotations_file_train)\n",
    "    data_frame_train = data_frame_train[data_frame_train['file'] == 'S04_1.pkl']\n",
    "    data_frame_train = data_frame_train.drop(['labels'], axis=1)\n",
    "    data_frame_train['type'] = 'train'\n",
    "\n",
    "    data_frame_test = pd.read_pickle(annotations_file_test)\n",
    "    data_frame_test = data_frame_test[data_frame_test['file'] == 'S04_1.pkl']\n",
    "    data_frame_test = data_frame_test.drop(['labels'], axis=1)\n",
    "    data_frame_test['type'] = 'test'\n",
    "    \n",
    "    \n",
    "    join_data_frame = pd.concat([data_frame_train, data_frame_test], ignore_index=True)\n",
    "    join_data_frame.to_csv(\"JOINED.csv\", index=False)\n",
    "\n",
    "    result = pd.merge(timestamps, join_data_frame, on='index', how='inner')\n",
    "\n",
    "    result['uid'] = result['index']\n",
    "    result['participant_id'] = 'S04'\n",
    "    result['video_id'] = 'S04_01'\n",
    "    result['verb'] = result['description_x']\n",
    "    result['narration'] = result['description_x']\n",
    "    result['verb_class'] = result['description_x'].apply(lambda x: activities_to_classify.index(x))\n",
    "\n",
    "    result = result[\n",
    "        ['uid', 'participant_id', 'video_id', 'narration', 'start_timestamp', 'stop_timestamp', 'start_frame',\n",
    "         'stop_frame', 'verb', 'verb_class', 'type']]\n",
    "    \n",
    "    \n",
    "    #result = fill_missing_intervals(result)\n",
    "    \n",
    "    result = result.sort_values(by='start_frame')\n",
    "    result['uid'] = range(len(result))\n",
    "    \n",
    "    train_proportion = 0.7\n",
    "\n",
    "    none_rows = result[result['type'].isna()]\n",
    "\n",
    "    num_train = int(len(none_rows) * train_proportion)\n",
    "\n",
    "    train_indices = none_rows.sample(n=num_train, random_state=42).index\n",
    "    result.loc[train_indices, 'type'] = 'train'\n",
    "\n",
    "    test_indices = none_rows.drop(train_indices).index\n",
    "    result.loc[test_indices, 'type'] = 'test'\n",
    "    \n",
    "    result = extend_video_id(result)\n",
    "    result = split_rows(result)\n",
    "    result['uid'] = range(len(result))\n",
    "    \n",
    "    \n",
    "    test = result[result['type'] == 'test']\n",
    "    test.to_csv(\"S04_test.csv\", index=False)\n",
    "    test.to_pickle(\"S04_test.pkl\")\n",
    "    train = result[result['type'] == 'train']\n",
    "    train.to_csv(\"S04_train.csv\", index=False)\n",
    "    train.to_pickle(\"S04_train.pkl\")\n",
    "    \n",
    "    \n",
    "    #result['uid'] = range(len(result))\n",
    "    result.to_pickle(f\"JOINED.pkl\")\n",
    "    result.to_csv(f\"JOINED.csv\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T16:44:37.476447Z",
     "start_time": "2024-02-12T16:44:37.470952Z"
    }
   },
   "id": "f7288622a8212497",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "create_annotations_file('S04_1.pkl', 'action-net/ActionNet_test.pkl', 'action-net/ActionNet_train.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T16:44:38.293448Z",
     "start_time": "2024-02-12T16:44:38.189438Z"
    }
   },
   "id": "841996d94829b09f",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8f1fcf4574a8ee33"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
